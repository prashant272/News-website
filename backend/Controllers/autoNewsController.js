const { scrapeNews, getLatestLinks } = require("../Services/scraperService");
const generateArticle = require("../Services/aiService");
const NewsArticle = require("../Models/NewsArticle");
const newsSources = require("../Config/newsSources");
const cloudinary = require("cloudinary").v2;
const crypto = require("crypto");

cloudinary.config({
    cloud_name: process.env.CLOUD_NAME,
    api_key: process.env.API_KEY,
    api_secret: process.env.API_SECRET,
});

// Helper to create slug
const createSlug = (title) => {
    return title
        .toLowerCase()
        .replace(/[^a-z0-9]+/g, "-")
        .replace(/(^-|-$)+/g, "");
};

// Helper: Upload Image to Cloudinary
const uploadImage = async (imageUrl) => {
    if (!imageUrl) return null;
    try {
        const response = await cloudinary.uploader.upload(imageUrl, {
            folder: "auto_news",
            fetch_format: "auto",
            quality: "auto" // Optimize size
        });
        return response.secure_url;
    } catch (error) {
        console.error("Cloudinary Upload Error:", error.message);
        return null; // Fail gracefully
    }
};

// Helper: Generate URL Hash
const generateUrlHash = (url) => {
    return crypto.createHash("sha256").update(url).digest("hex");
};

// Helper: Simple Semantic Check (Keyword Overlap)
const isSemanticDuplicate = (newTitle, existingTitles) => {
    if (!newTitle || !existingTitles.length) return false;

    const normalize = (str) => str.toLowerCase().replace(/[^\w\s]/g, "").split(/\s+/).filter(w => w.length > 3);
    const newWords = new Set(normalize(newTitle));

    if (newWords.size < 3) return false; // Too short to deduplicate reliably

    for (const title of existingTitles) {
        const existingWords = normalize(title);
        let matchCount = 0;
        for (const word of existingWords) {
            if (newWords.has(word)) matchCount++;
        }

        // If more than 60% of keywords match, consider it a semantic duplicate
        const similarity = matchCount / Math.min(newWords.size, existingWords.size);
        if (similarity > 0.6) return true;
    }
    return false;
};

// 1. Manual Single URL Processing
const autoGenerateNews = async (req, res) => {
    try {
        const { url, category } = req.body;

        if (!url || !category) {
            return res.status(400).json({
                success: false,
                msg: "URL and Category are required."
            });
        }

        const scraped = await scrapeNews(url);
        const aiData = await generateArticle(scraped.facts);
        const slug = createSlug(aiData.title || scraped.title);

        const urlHash = generateUrlHash(url);

        // Check technical duplicate
        const existing = await NewsArticle.findOne({
            $or: [
                { slug: slug },
                { urlHash: urlHash }
            ]
        });

        if (existing) {
            return res.status(409).json({ success: false, msg: "News article (or source URL) already exists.", slug: slug });
        }

        // Check semantic duplicate (within last 24 hours)
        const dayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000);
        const recentArticles = await NewsArticle.find({ createdAt: { $gt: dayAgo } }).select("title").lean();
        const recentTitles = recentArticles.map(a => a.title);

        if (isSemanticDuplicate(aiData.title || scraped.title, recentTitles)) {
            return res.status(409).json({ success: false, msg: "A very similar news article was already posted recently." });
        }

        // Upload Image
        let finalImage = null;
        if (scraped.image) {
            finalImage = await uploadImage(scraped.image);
        }

        const newPost = new NewsArticle({
            title: aiData.title || scraped.title,
            slug: slug,
            category: category.toLowerCase(),
            subCategory: aiData.subCategory || "General",
            summary: aiData.summary,
            content: aiData.content,
            image: finalImage,
            tags: aiData.tags || [],
            source: scraped.source,
            urlHash: urlHash,
            autoGenerated: true,
            status: "draft",
            author: "AI Writer",
            isLatest: false,
            isTrending: false,
            isHidden: true
        });

        await newPost.save();

        res.json({ success: true, msg: "News auto-generated.", post: newPost });

    } catch (error) {
        console.error("Auto-News Error:", error);
        res.status(500).json({ error: error.message });
    }
};

// 2. Batch Processing for RSS Feeds
const fetchAndProcessNews = async (req, res) => {
    try {
        let stats = {
            processed: 0,
            duplicates: 0,
            errors: 0,
            articles: []
        };

        // Iterate through all sources
        for (const source of newsSources) {
            console.log(`Checking Source: ${source.name}...`);

            // 1. Get latest links from RSS
            const items = await getLatestLinks(source.url);

            let newItemsCount = 0;
            const MAX_NEW_PER_SOURCE = 2; // Only fetch 2 new items per source per run

            for (const item of items) {
                if (newItemsCount >= MAX_NEW_PER_SOURCE) break;

                const urlHash = generateUrlHash(item.link);
                const slug = createSlug(item.title);
                const category = source.category;

                // 2. Check for Technical Duplicates
                const duplicate = await NewsArticle.findOne({
                    $or: [
                        { slug: slug },
                        { urlHash: urlHash },
                        { title: item.title }
                    ]
                });

                if (duplicate) {
                    console.log(`Skipping Duplicate: ${item.title}`);
                    stats.duplicates++;
                    continue;
                }

                // 3. Simple Semantic Deduplication (Check against what we already have in memory from recent runs/DB)
                const dayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000);
                const recentArticles = await NewsArticle.find({ createdAt: { $gt: dayAgo } }).select("title").lean();
                const recentTitles = recentArticles.map(a => a.title);

                if (isSemanticDuplicate(item.title, recentTitles)) {
                    console.log(`Skipping Semantic Duplicate: ${item.title}`);
                    stats.duplicates++;
                    continue;
                }

                // 4. Process New Article
                try {
                    console.log(`Scraping: ${item.title}`);
                    const scraped = await scrapeNews(item.link);

                    console.log(`Generating AI Content...`);
                    const aiData = await generateArticle(scraped.facts);

                    // Use AI title if decent, or fallback to RSS title
                    const finalTitle = aiData.title && aiData.title.length > 10 ? aiData.title : scraped.title;
                    const finalSlug = createSlug(finalTitle);

                    // Re-check slug collision after AI title gen
                    const slugCollision = await NewsArticle.findOne({ slug: finalSlug });
                    if (slugCollision) {
                        console.log(`Skipping Slug Collision: ${finalSlug}`);
                        stats.duplicates++;
                        continue;
                    }

                    // Upload Image if exists
                    let finalImage = null;
                    if (scraped.image) {
                        finalImage = await uploadImage(scraped.image);
                    }

                    const newPost = new NewsArticle({
                        title: finalTitle,
                        slug: finalSlug,
                        category: category.toLowerCase(),
                        subCategory: aiData.subCategory || "General",
                        summary: aiData.summary,
                        content: aiData.content,
                        image: finalImage,
                        tags: aiData.tags || [],
                        source: source.name,
                        urlHash: urlHash,
                        autoGenerated: true,
                        status: "draft",
                        author: "AI News Bot",
                        isLatest: false,
                        isTrending: false,
                        isHidden: true,
                        createdAt: new Date()
                    });

                    await newPost.save();

                    stats.processed++;
                    stats.articles.push(finalTitle);
                    newItemsCount++;

                    // Add a small delay
                    await new Promise(resolve => setTimeout(resolve, 2000));

                } catch (err) {
                    console.error(`Failed to process ${item.link}:`, err.message);
                    stats.errors++;
                }
            }
        }

        res.json({
            success: true,
            msg: "Batch processing completed.",
            stats
        });

    } catch (error) {
        console.error("Batch Process Error:", error);
        res.status(500).json({ error: "Batch processing failed." });
    }
};

// 3. Get All AI Drafts
const getAutoGeneratedDrafts = async (req, res) => {
    try {
        const drafts = await NewsArticle.find({
            autoGenerated: true,
            status: "draft"
        }).sort({ createdAt: -1 });

        res.json({
            success: true,
            count: drafts.length,
            drafts: drafts
        });

    } catch (error) {
        console.error("Get Drafts Error:", error);
        res.status(500).json({ error: "Failed to fetch drafts." });
    }
};

// 4. Cleanup Duplicates (Refactored for new Schema)
const cleanupDuplicates = async (req, res) => {
    try {
        const duplicates = await NewsArticle.aggregate([
            {
                $group: {
                    _id: { slug: "$slug" },
                    regexCount: { $sum: 1 },
                    ids: { $push: "$_id" }
                }
            },
            {
                $match: {
                    regexCount: { $gt: 1 }
                }
            }
        ]);

        let totalRemoved = 0;
        for (const doc of duplicates) {
            // Keep the first one, delete the rest
            const idsToDelete = doc.ids.slice(1);
            const result = await NewsArticle.deleteMany({ _id: { $in: idsToDelete } });
            totalRemoved += result.deletedCount;
        }

        res.json({
            success: true,
            msg: `Cleanup completed. Removed ${totalRemoved} duplicate items.`,
            removed: totalRemoved
        });

    } catch (error) {
        console.error("Cleanup Error:", error);
        res.status(500).json({ error: "Cleanup failed." });
    }
};

module.exports = { autoGenerateNews, fetchAndProcessNews, getAutoGeneratedDrafts, cleanupDuplicates };
