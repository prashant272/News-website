const { scrapeNews, getLatestLinks } = require("../Services/scraperService");
const generateArticle = require("../Services/aiService");
const NewsConfig = require("../Models/news.model");
const newsSources = require("../Config/newsSources");

// Helper to create slug
const createSlug = (title) => {
    return title
        .toLowerCase()
        .replace(/[^a-z0-9]+/g, "-")
        .replace(/(^-|-$)+/g, "");
};

// 1. Manual Single URL Processing
const autoGenerateNews = async (req, res) => {
    try {
        const { url, category } = req.body;

        if (!url || !category) {
            return res.status(400).json({
                success: false,
                msg: "URL and Category are required."
            });
        }

        const scraped = await scrapeNews(url);
        const aiData = await generateArticle(scraped.facts);
        const slug = createSlug(aiData.title || scraped.title);

        const newPost = {
            title: aiData.title || scraped.title,
            slug: slug,
            category: category,
            subCategory: aiData.subCategory || "General",
            summary: aiData.summary,
            content: aiData.content,
            image: scraped.image || null,
            tags: aiData.tags || [],
            source: scraped.source,
            autoGenerated: true,
            status: "draft",
            author: "AI Writer",
            isLatest: false,
            isTrending: false,
            isHidden: true
        };

        let newsConfig = await NewsConfig.findOne({ isActive: true });
        if (!newsConfig) newsConfig = new NewsConfig({ isActive: true });

        if (!newsConfig[category]) {
            return res.status(400).json({ success: false, msg: `Invalid category: ${category}` });
        }

        const duplicate = newsConfig[category].find(item => item.slug === slug);
        if (duplicate) {
            return res.status(409).json({ success: false, msg: "News article already exists.", slug: slug });
        }

        newsConfig[category].unshift(newPost);
        newsConfig.lastUpdated = new Date();
        await newsConfig.save();

        res.json({ success: true, msg: "News auto-generated.", post: newPost });

    } catch (error) {
        console.error("Auto-News Error:", error);
        res.status(500).json({ error: error.message });
    }
};

// 2. Batch Processing for RSS Feeds
const fetchAndProcessNews = async (req, res) => {
    try {
        let stats = {
            processed: 0,
            duplicates: 0,
            errors: 0,
            articles: []
        };

        const newsConfig = await NewsConfig.findOne({ isActive: true }) || new NewsConfig({ isActive: true });

        // Iterate through all sources
        for (const source of newsSources) {
            console.log(`Checking Source: ${source.name}...`);

            // 1. Get latest links from RSS
            const items = await getLatestLinks(source.url);

            let newItemsCount = 0;
            const MAX_NEW_PER_SOURCE = 2; // Only fetch 2 new items per source per run

            for (const item of items) {
                if (newItemsCount >= MAX_NEW_PER_SOURCE) break;

                const slug = createSlug(item.title);
                const category = source.category;

                // 2. Check for Duplicates in DB (Strict check on Target Link OR Slug)
                if (newsConfig[category]) {
                    const isDuplicate = newsConfig[category].some(existing =>
                        existing.slug === slug ||
                        (existing.targetLink && existing.targetLink === item.link) ||
                        existing.title === item.title
                    );

                    if (isDuplicate) {
                        console.log(`Skipping Duplicate: ${item.title}`);
                        stats.duplicates++;
                        continue;
                    }
                } else {
                    newsConfig[category] = []; // Initialize if missing
                }

                // 3. Process New Article
                try {
                    console.log(`Scraping: ${item.title}`);
                    const scraped = await scrapeNews(item.link);

                    console.log(`Generating AI Content...`);
                    const aiData = await generateArticle(scraped.facts);
                    console.log("AI Data Received:", JSON.stringify(aiData, null, 2));

                    // Use AI title if decent, or fallback to RSS title
                    const finalTitle = aiData.title && aiData.title.length > 10 ? aiData.title : scraped.title;
                    const finalSlug = createSlug(finalTitle);

                    const newPost = {
                        title: finalTitle,
                        slug: finalSlug,
                        category: category,
                        subCategory: aiData.subCategory || "General",
                        summary: aiData.summary,
                        content: aiData.content,
                        image: scraped.image || null,
                        tags: aiData.tags || [],
                        source: source.name,  // Use Source Name
                        targetLink: item.link,
                        autoGenerated: true,
                        status: "draft",
                        author: "AI News Bot",
                        isLatest: false,
                        isTrending: false,
                        isHidden: true,
                        createdAt: new Date()
                    };

                    newsConfig[category].unshift(newPost);
                    stats.processed++;
                    stats.articles.push(finalTitle);
                    newItemsCount++;

                    // Add a small delay to avoid hitting OpenAI rate limits too hard
                    await new Promise(resolve => setTimeout(resolve, 2000));

                } catch (err) {
                    console.error(`Failed to process ${item.link}:`, err.message);
                    stats.errors++;
                }
            }
        }

        if (stats.processed > 0) {
            newsConfig.lastUpdated = new Date();
            await newsConfig.save();
        }

        res.json({
            success: true,
            msg: "Batch processing completed.",
            stats
        });

    } catch (error) {
        console.error("Batch Process Error:", error);
        res.status(500).json({ error: "Batch processing failed." });
    }
};

// 3. Get All AI Drafts
const getAutoGeneratedDrafts = async (req, res) => {
    console.log("ðŸ‘‰ /auto-news/drafts HIT! Fetching config...");
    try {
        const newsConfig = await NewsConfig.findOne({ isActive: true }).lean();
        console.log("Config Result:", newsConfig ? "Found" : "Not Found");

        if (!newsConfig) {
            return res.status(404).json({ success: false, msg: "Config not found" });
        }

        let allDrafts = [];
        const categories = ["home", "india", "sports", "business", "technology", "entertainment", "lifestyle", "world", "health"];

        categories.forEach(cat => {
            if (newsConfig[cat]) {
                const drafts = newsConfig[cat]
                    .filter(item => item.autoGenerated === true && item.status === 'draft')
                    .map(item => ({ ...item, category: cat })); // Add category to item for display
                allDrafts = [...allDrafts, ...drafts];
            }
        });

        // Sort by newest first (assuming internal _id or we can use generic sort if timestamp wasn't in subdoc)
        // Note: Subdocs might not have createdAt unless defined in schema, but we can reverse since we unshift

        res.json({
            success: true,
            count: allDrafts.length,
            drafts: allDrafts
        });

    } catch (error) {
        console.error("Get Drafts Error:", error);
        res.status(500).json({ error: "Failed to fetch drafts." });
    }
};

// 4. Cleanup Duplicates
const cleanupDuplicates = async (req, res) => {
    try {
        const newsConfig = await NewsConfig.findOne({ isActive: true });
        if (!newsConfig) {
            return res.status(404).json({ success: false, msg: "Config not found" });
        }

        let totalRemoved = 0;
        const categories = ["home", "india", "sports", "business", "technology", "entertainment", "lifestyle", "world", "health"];

        categories.forEach(cat => {
            if (newsConfig[cat] && newsConfig[cat].length > 0) {
                const seenTitle = new Set();
                const seenLink = new Set();
                const uniqueItems = [];

                newsConfig[cat].forEach(item => {
                    const titleKey = item.title ? item.title.toLowerCase().trim() : '';
                    const linkKey = item.targetLink || '';

                    // Check if duplicate
                    if ((titleKey && seenTitle.has(titleKey)) || (linkKey && seenLink.has(linkKey))) {
                        totalRemoved++;
                    } else {
                        if (titleKey) seenTitle.add(titleKey);
                        if (linkKey) seenLink.add(linkKey);
                        uniqueItems.push(item);
                    }
                });

                newsConfig[cat] = uniqueItems;
            }
        });

        if (totalRemoved > 0) {
            newsConfig.markModified('india');
            // markModified is needed if we replace arrays, though mongoose usually detects it. 
            // Being safe: mark all potential categories modified if needed, or just save.
            await newsConfig.save();
        }

        res.json({
            success: true,
            msg: `Cleanup completed. Removed ${totalRemoved} duplicate items.`,
            removed: totalRemoved
        });

    } catch (error) {
        console.error("Cleanup Error:", error);
        res.status(500).json({ error: "Cleanup failed." });
    }
};

module.exports = { autoGenerateNews, fetchAndProcessNews, getAutoGeneratedDrafts, cleanupDuplicates };

